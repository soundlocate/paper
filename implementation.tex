\section{Umsetzung der einzelnen Module} \todo{Durchlesen + überprüfen}
Der Kern unserer Idee ist die Richtungsbestimmung, die aus den Phasendifferenzen der verschiedenen Wellen bei verschiedenen Mikrofonen eine Richtung berechnet. Um diese Komponente überprüfen und das Verfahren anwenden zu können, haben wir die verschiedenen Module implementiert. Hierbei haben wir diese wie vorgesehen so universell umgesetzt, dass wir das Richtungsbestimmungsmodul sowohl mithilfe einer Simulation als auch mithilfe eines praktischen Aufbaus evaluieren können. Das nachfolgende Kapitel beschreibt eben diese Umsetzung in der Reihenfolge, mit der das Signal verarbeitet wird; von der Aufnahme der Schallquellen bis zur Ausgabe der Positionsdaten.

\subsection{Simulation (Modul 1)}
Um die Richtungsbestimmung unabhängig von Störfaktoren wie Rauschen und der Reflektion des Schalls an Wänden oder anderen Gegenständen zu überprüfen, haben wir zunächst eine Simulation entwickelt. Außerdem lässt sich mit dieser gezielt der Einfluss verschiedener Störfaktoren untersuchen. Die Simulation kann beliebig viele Mikrofone an beliebigen Positionen simulieren. Leider konnten wir keine bestehenden Lösungen für die Simulation von dreidimensionalem Ton, wie \textit{OpenAL} \cite{OpenAL}, welches eine Programmbibliothek für die Simulation von Schall ist, verwenden, da bei diesen die Anzahl der Mikrofone limitiert ist und die Phase des Audiosignals in der Simulation vernachlässigt wird. Da die Funktion unserer Richtungsbestimmung unabhängig von den Amplituden der Schallquellen bei den einzelnen Mikrofonen ist, haben wir unsere Simulation rein auf die Phase und die Laufzeit beschränkt. Um eine interaktive Benutzung und eine leichte Überprüfung der Richtungsbestimmumg zu gewährleisten, besitzt die Simulation eine graphische Benutzeroberfläche, mit der man interaktiv Schallquellen hinzufügen und entfernen kann. Außerdem kann die Simulation auch die georteten Richtungen darstellen und ermöglicht damit einen einfachen Vergleich der georteten und tatsächlichen Positionen. Das Simulationsmodul wurde in der Programmiersprache \textit{C++} implementiert, da diese eine gute \textit{OpenGL} Integration bietet.

\begin{figure}[H]
  \includegraphics[width=\linewidth]{img/bildsimulation}
  \caption{Screenshot der Simulation, die roten Punkte stellen die Mikrofone dar, die schwarzen die Schallquellen und die grünen die georteten Positionen}
\end{figure}

\subsection{Hardware (Modul 1)}
Um das durch die Simulation evaluierbare Verfahren praktisch zu testen und zu nutzen, muss nur die Quelle der Daten, also das erste Modul, ausgetauscht werden. Die Aufgabe des ersten Moduls ist es nun nicht mehr, virtuelle Mikrofone, welche die Aufnahme von virtuellen Schallquellen simulieren zu produzieren, sondern die Signale echter Mikrofone, welche echte Schallquellen aufnehmen, einzulesen. Um dies zu realisieren, benötigt man zum einen Mikrofone und zum anderen Hardware, welche die Signale, die von den Mikrofonen kommen, digitalisiert und für einen Computer zugänglich macht. Zusätzlich benötigt man eine neue Implementierung der Software des ersten Moduls, die die Daten von der Hardware annimmt und an das zweite Modul weiterleitet. Hierbei kommen wieder die Vorteile unserer modularen Vorgehensweise zum tragen, da nur das erste Modul ersetzt werden muss und die gesamte restliche Software beibehalten werden kann. Dies sorgt auch dafür, dass die Simulation und die Realwelttests immer die gleichen Auswertungsalgorithmen verwenden und so sehr gut vergleichbar sind.

\subsubsection{Mikrofone}
Die erste Komponente, die es bei einem realen Aufbau der Messapparatur eine wichtige Rolle spielt, ist die der Schallwandlung. Dies wird durch Mikrofone realisiert, an die es einige Anforderungen gibt. Die wichtigste Anforderung ist, dass sie eine möglichst gleichmäßige Richtcharakteristik haben.
Eine weitere Anforderung ist, dass sie möglichst klein sind, da der Abstand zwischen ihnen nicht zu groß sein darf, um die obere Grenzfrequenz möglichst hoch zu setzen, da der Abstand der Mikrofone nicht größer als $\lambda$ der zu lokalisierenden Frequenz ist. Des weiteren sollte das Signal-Rausch-Verhältnis möglichst groß sein, da Rauschen die Messungen unpräziser macht \cite{Rausch}.\\
\\
Wir haben uns dafür entschieden, Elektretmikrofonkapseln zu verwenden, da diese gängig sind, einfach beschaltet werden können und die oben aufgeführten Anforderungen relativ gut erfüllen \cite{elektret}.
Die meisten für uns relevanten Parameter der Mikrofone konnten wir aus den Datenblättern entnehmen. Eine Ausnahme hiervon ist die Richtcharakteristik, welche jedoch für uns sehr wichtig ist, da sie die Messqualität sehr stark beeinflusst. Diese sollte möglichst gleichmäßig sein, da nur so aus allen Richtungen Daten von gleicher Qualität aufgenommen werden können. Wenn zum Beispiel alle Mikrofone eine Nierencharakteristik aufweisen und sie in einem gleichseitigen Dreieck angeordnet sind, liefert mindestens ein Mikrofon ein deutlich schwächeres Signal als die anderen, was dazu führt, das die Phasenlage der einzelnen Wellen ungenauer bestimmt werden und mit ihnen auch die Lokalisation.\\
Um unter diesem Aspekt geeignete Mikrofone zu finden, haben wir die Richtcharakteristiken verschiedener Mikrofone mittels einer selbst entwickelten Messapparatur und einer selbst entwickelten Messsoftware vermessen. Die hierfür entwickelte Messapparatur sendet mittels eines Lautsprechers eine Sinus-Schwingung aus und misst, wie stark diese vom Mikrofon aufgenommen wurde. Danach dreht sie das Mikrofon um einen festgelegten Winkel weiter und fertigt erneut eine Messung an. Dieser Vorgang wird solange wiederholt, bis das Mikrofon einmal um 360$^{\circ}$ gedreht wurde.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{img/chara_mess}
  \caption{Unsere Messapparatur für die Charakteristik eines Mikrofons}
\end{figure}
Die so ermittelten Daten können nun mittels des freien Plottingprogramms \textit{gnuplot} \cite{Gnuplot} visualisiert werden, um die Richtcharakteristik abzulesen.
\begin{figure}[H]
  \centering
  \includegraphics[width=(0.45\linewidth)]{img/badMic}
  \includegraphics[width=(0.45\linewidth)]{img/goodMic}
  \caption{Auf den beiden Grafiken ist die gemessene Amplitude des Mikrofons über den Winkel aufgetragen. Bei der linken Grafik kann man feststellen, dass das vermessene Mikrofon eine sehr ungleichmäßige Charakteristik aufweist, diese Mikrofone haben wir zu Anfang verwendet. Auf der rechten Seite ist die Charakteristik der Mikrofone zu sehen, die wir in unserem aktuellen Testaufbau verwenden. Diese ist sehr gleichmäßig, weshalb wir die zuerst verwendeten Mikrofone durch diese Mikrofone ausgetauscht haben.}\label{fig:caracter}
\end{figure}
Für die reale Messapparatur haben wir vier Mikrofone in einem Tetraeder angeordnet. Um die Charakteristik der Mikrofone möglichst wenig zu verändern, haben wir die Mikrofone nur an ihrem Kabel mit dem Tetraeder verbunden. Dadurch ist der Schallschatten durch den Tetraeder relativ gering.
\begin{figure}{H}
  \begin{center}
    \includegraphics[width=0.35\linewidth]{img/tet}
  \end{center}
  \caption{Aufbau unserer Messapparatur}
\end{figure}
\subsubsection{Audio Interface}
Auch an das Audio-Interface, also die Verbindung von Mikrofonen zum Computer, gab es bestimmte Voraussetzungen. So sollte es z.B. eine möglichst hohe Abtastrate und einen möglichst großen Dynamikumfang haben, da hierdurch die von der Fourier-Transformation bestimmte Phase und hiermit die Lokalisation genauer wird\cite{sample}. Außerdem haben diese beiden Faktoren Einfluss auf die Tonqualität. Hierbei war der Auswahlprozess allerdings weniger aufwändig, da wir auf "normale" Hardware aus dem Consumer-Markt zurückgreifen konnten. Um die Elekretmikrofonkapseln an das Audiointerface anzuschließen, benötigt man zusätzlich eine Schaltung, welche das unsymmetrische Signal der Elekretmilrofonkapsel in ein symmetrisches Signal für das Audio-Interface umwandelt. Außerdem muss diese die Phantomspeisung, die das Audio-Interface bereit stellt und eine Spannung von 48V hat, in eine Tonaderspeisung für das Mikrofon konvertieren. Hierfür kommt die Schaltung von \cite{Powering_microphones} zum Einsatz (siehe Abbildung \ref{fig:scematics} im Anhang).

\subsubsection{Software}
Um die echten Mikrofone für die Ortung zu verwenden, muss noch eine Verbindung zwischen dem Audio Interface und dem nächsten Modul geschaffen werden. Durch unseren modularen Aufbau lässt sie dies leicht implementieren. Wir haben dazu ein Programm in Java entwickelt, dass fähig ist, mehrkanalige Audiosignale in Echtzeit aufzunehmen und über TCP/IP an die Fourier-Transformation weiterzuleiten. Zur Umsetzung haben wir die Programmbibliothek \textit{portaudio} \cite{portaudio} verwendet. Diese Programmbibliothek hat den Vorteil, dass mehrere Audiokanäle zeitsynchronisiert eingelesen werden können, was sehr wichtig ist, damit unser Ortungsverfahren, welches auf der relativen Phasenlage basiert, funktioniert. \textit{Portaudio} wurde unter Java über das Java Native Interface (JNI) benutzt.

\subsection{Fourier-Transformation (Modul 2)}
Dieses Modul teilt die Audio-Signale in einzelnen Sinuswellen und bestimmt deren Phase und Amplitude. Um dies zu bewerkstelligen, lässt sich eine diskrete Fourier-Transformation verwenden. Die diskrete Fourier-Transformation bestimmt aus einem zeitdiskretem Signal die einzelnen Sinusschwingungen, mit ihrer zugehörigen Phase und Amplitude, die zusammen das Signal bilden. Ein schneller Algorithmus um die diskrete Fourier-Transformation eines Signals zu berechnen ist die Fast Fourier-Transformation (FFT). Dieser ist schnell genug, um eine Echtzeitverarbeitung des Signals zu ermöglichen. Als Implementation der FFT haben wir \textit{FFTW}\cite{FFTW} verwendet, da \textit{FFTW} kostenlos, opensource und vergleichsweise schnell ist.
Auch das Fourier-Transformations Modul wurde aus Performancegründen in \textit{C++} implementiert.\\
Aus einer diskrete Fourier-Transformation von $n$ reellen Zahlen erhält man eine Liste aus $n$ komplexen Zahlen um. Eine komplexe Zahl $z$ an der Stelle $i$ enthält die Amplituden- und Phaseninformation für die Frequenz $f$:
$$
f = \frac{i\cdot r}{n}
$$
$r$ ist dabei die Abtastrate des Signals. Die Amplitude $A$ des Sinus lässt sich mit dem Betrag der komplexen Zahl berechnen und die Phase $\phi$ mit dem Arcus-Tangens, dies entspricht der Koordinatentransformation von einem kartesischem in das polare Koordinatensystem:

\begin{minipage}{0.49\textwidth}
  $$
  A = \sqrt[]{{\Re(z)}^2 + {\Im(z)}^2}
  $$
  $$
  \phi = \operatorname{atan2}(\Im(z), \Re(z))
  $$
  $$
  \operatorname{atan2}(y,x) := \begin{cases} \arctan\frac{y}{x} & \mathrm{f\ddot ur}\ x > 0\\ \arctan\frac{y}{x} + \pi & \mathrm{f\ddot ur}\ x < 0,\ y \geq 0\\ \arctan\frac{y}{x} - \pi & \mathrm{f\ddot ur}\ x < 0,\ y < 0\\ +\pi/2 & \mathrm{f\ddot ur}\ x = 0,\ y > 0\\ -\pi/2 & \mathrm{f\ddot ur}\ x = 0,\ y < 0\\ 0 & \mathrm{f\ddot ur}\ x = 0,\ y = 0 \end{cases}
  $$
\end{minipage}
\begin{minipage}{0.49\textwidth}
  \begin{figure}[H]
    \centering
    \scalebox{.6}{\input{img/polarconvert.tex}}
    \caption{Transformation von kartesischen zu polaren Koordinatensystem}
    \label{fig:polarconvert}
  \end{figure}
\end{minipage}
Die Verwendung von $\operatorname{atan2}(y,x)$ anstelle von $\arctan\frac{y}{x}$ sorgt dafür, dass der richtige Winkel berechnet wird. $\arctan\frac{y}{x}$ liefert nur Winkel von -90\degree bis 90\degree, deswegen muss anhand des Vorzeichens von $x$ und $y$ bestimmt werden, in welchem Quadranten der Punkt liegt und der von $\arctan\frac{y}{x}$ gelieferte Winkel dementsprechend verschoben werden.

Das in Frequenz, Phase und Amplitude konvertierte Ergebnis der Fourier-Transformation wird dann gefiltert. Alle Frequenzen mit einer Amplitude, die kleiner als eine bestimmte Untergrenze sind, werden gelöscht. Die verbleibenden Frequenzen werden an das Ortungsmodul übermittelt.

\subsection{Ortungsmodul (Modul 3)}
Die von der Fourier-Transformation bestimmten Tripel aus Frequenz, Phase und Amplitude werden vom Ortungsmodul weiter verarbeitet. In das Ortungsmodul können verschiedene Methoden der Ortsbestimmung eingesetzt werden. So muss z.B. für die dreidimensionale Ortung ein anderes Verfahren verwendet werden, als für die zweidimensionale Ortung. Das Ortungsverfahren, das von dem Ortungsmodul verwendet wird, kann einfach ausgetauscht werden. Die ermittelten Positionen werden an die Ausgabe weitergesende,t um sie dort auszugeben oder zur Filterung des Audio-Signals zu verwenden. \\
Das Ortungsmodul ist in Java geschrieben.
\subsection{Ausgabemodul (Modul 4)}
Wir haben ein Beispiel-Ausgabemodul in Javascript implementiert. Mit diesem ist es möglich, die Positionsdaten zu visualisieren, was das unmittelbare Evaluieren stark vereinfacht. Die Programmiersprache Javascript haben wir gewählt, damit dieses Ausgabemodul auf jedem Endgerät mit modernem Webbrowser, wie z.B. Smartphones oder Laptops, ausgeführt werden kann.\\
Die Simulation enthält eine weitere Implementation eines Ausgabemoduls. Auch diese visualisiert die georteten Positionen, erlaubt es aber, diese auf der gleichen Benutzeroberfläche wie die Sollpositionen anzuzeigen. Dies gibt ein sehr direktes Feedback beim Entwickeln des Ortungsalgorithmus. Dieses letzte Modul könnte allerdings, dank unseres modularen Konzeptes, bei Bedarf auch anders, z.B. als Plugin für eine \textit{Digital Audio Workstation} (\textit{DAW}) implementiert werden.
\subsection{Testen der einzelnen Module}
Ein weiterer Vorteil der Modularität ist, dass jedes Modul unabhänig von den anderen Modulen funktionsfähig ist. Dadurch kann die korrekte Funktionsweise für jedes Modul einzeln überprüft werden und man kann Fehler besser lokalisieren. \\
Die Audiosimulation haben wir mithilfe eines selbstgeschriebenem Plotting Programms überprüft. Dieses stellt die von der Audiosimulation versendeten Samples in Abhängigkeit der Zeit dar. Damit kann manuell die Phasendifferenz von dem Graphen abgelesen und mit dem erwartetem Wert verglichen werden.
\begin{figure} [H]
  \includegraphics[width=\linewidth]{img/glplot}
  \caption{Screenshot unseres Plotting Programms}
  \label{fig:glplot}
\end{figure}

Die Fourier-Transformation konnten wir mit der vorher überprüften Audiosimulation testen. Dazu haben wir die von der Fourier-Transformation bestimmten Frequenz, Phase und Amplitude Tripel mit den tatsächlich in der Simulation eingestellten Werten verglichen.\\
Durch das Testen der einzelnen Module konnten wir effizient die vorhandenen Fehler, wie die falsche Berechnung der Phase und einen Fehler in der Distanzberechnung der Audiosimulation, finden und beheben.
